[{"authors":null,"categories":[],"content":"Welcome to this noob tutorial on how to get your own website online, quick and for free.\nFirst off you should know that this is NOT a complete guide on how to fully operate your future website and all the vast possibilities. I will happily lead you to the moment of the deployment and the emotion of having your own website on the web. To go further i suggest two main sources of great information that are:\n blogdown: Creating Websites with R Markdown by Yihui Xie, Amber Thomas, Alison Presmanes Hill Up and running with blogdown, by Alison Presmanes  Those above are the creators and the masters of blogdown, therefore i strongly suggest reading them.\nWell, now, without further ado, let\u0026rsquo;s get to it!\nI assume that you already have R and R-studio installed on your computer. So I\u0026rsquo;ll skip ahead.\nLet\u0026rsquo;s start from installing some packages:\n install R \u0026ldquo;devtools\u0026rdquo; install the package \u0026lsquo;blogdown\u0026rsquo; then you should load it then install \u0026lsquo;Hugo\u0026rsquo;  to do this you can copy paste these lines into your R console if you are too lazy to type:\ninstall.packages(\u0026quot;devtools\u0026quot;) #1. install R 'devtools' install.packages(\u0026quot;blogdown\u0026quot;) #2.installing 'blogdown' package library(blogdown) #3. loading it blogdown::install_hugo() #4. installing hugo  after a bit Hugo is installed. From now on things get more complicated, yeah i know we just started!\nBUT it is because we here introduce the use of git.\ngit is a version control system that basically allows you to save all your steps and go back if you screw something up (if you know how to use it properly\u0026hellip;). Since this is a noob tutorial i won\u0026rsquo;t go into details on how git works, i will let this to your good willing to learn something new today. Moving on.\nThe first thing you want to do is to create your own repository on github\nIf you don\u0026rsquo;t know what I am talking about it means that you probably have to subscribe to the website first https://github.com/, it\u0026rsquo;s free! Come one! DO IT\nfollow the instruction on screen and you are good to go.\nwhen you have your own github account, you can now create your first repository.\nto do that, you click on the plus sign of the screen after you subscribed:\nNow choose a name for you project, e.g. \u0026ldquo;MyWebsite\u0026rdquo;\nit is very important that you select the option to initialize your repository with a README file. now you should just click on the green button \u0026ldquo;clone or download\u0026rdquo;\nselect the URL and copy it, you will need it in R-studio.\nNow go to R-studio, you can see that on the bottom of the GUI, there are two panels, one is called Console, where you can input commands to R. The other is called \u0026ldquo;Terminal\u0026rdquo;, this is an emulator of your computer terminal, where commands directly influence your computer environment, thus be careful to not mess thing up.\nSelect the terminal panel, you will notice a command line slightly different from the one you are used to on R.\nalso before the command prompt, you will see your working directory you are in right now. In my case it is under \u0026ldquo;C:\\Users\\zephi\\Dropbox\\SeaEcoLab\u0026gt;\u0026rdquo;\nYou should now move to the directory in which you will create your new project. Mind that we will create another folder in the following step, so it will be a sub folder of the directory you choose to start with. If you are happy with the default choice and want to create your folder right now just go ahead and type git clone and copy paste the URL you copied from github.\ngit clone https://github.com/Fabbiologia/MyWebsite.git  It should appear your URL instead of mine (duh\u0026hellip;)\nyou can also clone directly to other folders, but to do that i will link you to another site with a nice tutorial on how to do that: https://www.atlassian.com/git/tutorials/setting-up-a-repository/git-clone\nNow, you generated a copy of the repository you created on the github website in your computer, so just go ahead and change your working directory to the one you created:\ncd MyWebsite  you just change \u0026ldquo;MyWebsite\u0026rdquo; with the name you choose.\nNow you have a working directory that is linked to github, this will help you a lot to improve your workflow, and also to be able to deploy your website at the end of this tutorial.\nnow it is time to get to the cool part.\nUse the top menu buttons in RStudio to select File -\u0026gt; New Project -\u0026gt; Existing Directory, then browse to the directory on your computer where your GitHub repo is and click on the Create Project button.\nThis will transfer you to your project in RStudio. You should now edit your *gitignore file. You can find it in the files pane (bottom right corner panel).\nthe file should contain the following:\n.Rproj.user .Rhistory .RData .Ruserdata blogdown .DS_Store # if a windows user, Thumbs.db instead public/ # if using Netlify\nif some of these files are missing you should add them, you can just copy paste them from here. Mind the .DS_Store file. You should add this only if you are a Mac user, if you are a windows user you should add Thumbs.db instead.\nNow it is time to create your website with the academic theme. You do that by giving this command on the R console:\nblogdown::new_site(theme = \u0026quot;gcushen/hugo-academic\u0026quot;, theme_example = TRUE)  Now go to the top toolbar, and click on Tools and then click project options from the menu. there you should uncheck the \u0026ldquo;preview site after build\u0026rdquo; options under the build tools.\nYou are almost there! Now you should edit your config.toml file. Click it from the File pane as you did for the gitignore file and it should open. The first thing you want to do is to change the URL file under the baseurl option at the beginning of the script.\nNow its time to choose your site name. This can be whatever you want, but for this tutorial we will use netlify to deploy it (put it online :) ) so it should be like this:\nbaseurl = \u0026ldquo;https://MySiteName.netlify.com/\u0026quot;\nalso remember to add the / trailing slash at the end of the URL.\nYou can go ahead and edit all of the other elements, the instruction on how to modify it are very straightforward. This will allow you to add your own information, pictures and files.\nWhen you are satisfied with your changes, you should commit your changes and push to GitHub. To do this, you should notice that in the top-right pane in RStudio there are several panels. One of which is called Git. There you will see all the file you changed and that are different from the online repository, thus you need to \u0026ldquo;commit\u0026rdquo;.\nnow you can check all of the files you find these will change the colors icon of their status.\nNow here i had a problem in my first commit. When you have large files that you want to commit to GitHub, RStudio might crash. That is a problem of this peculiar interface. If you experience such a problem you can easily go around it and do the following in your terminal panel in RStudio:\ngit add -A  this will automatically stage all of the changes. Now that your changed are staged you need to commit them, to do this go back to the git panel in RStudio, and click on the commit button on the toolbar.\nremember to put a message to your commit. You should always do that, explaining what you changed and updated, to keep track of your progress (and potential mistakes).\nNow go on and click commit. This will open a window with the progress of the commit. If everything goes fine, and no error messages are displayed, you should now click on the green arrow called Push. This will make all your changes immediately effective.\nNow do one last thing before go any further. Use this command to check your Hugo version. In the R console type:\nblogdown::hugo_version()  and take note of the version number in the output because you will need it in the next step, this is VERY IMPORTANT!!\nNow that you tweaked your website you want to know how to deploy your website. You should first go to Netlify website: https://www.netlify.com\nRegister following the instruction on screen.\nthen you should log in and select New site from Git. Click on the GitHub icon. From there, Netlify will allow you to select from your existing GitHub repositories. Pick the repository you created and then you should specify to things:\n the hugo version that you are using. the folder that contains your public files (the ones that will shape your website)  you will type the first in the settings you see here in the screenshot:\nYOU SHOULD PUT YOUR OWN VERSION NUMBER OF HUGO FOR THIS TO WORK! that is why you needed to check it before.\ngo on and click deploy!\nAfter a while your site will be deployed. But first you want to change your site name. To do this click on Site settings, and click on \u0026ldquo;change name\u0026rdquo;.\nThen you can change your name to the one you put in your config file. Actually, it need to be the same!!\nand now you are good to go! click on the link and if everything went fine you should be redirected to your brand new site!! Congratulations!!\nEvery time you make changes or add posts, you just need to commit your changes to GitHub, as you did for the first commit, and after few seconds netlify will automatically update your website!\nContact me if you have further question! you can find me on twitter, email, or on github. You will find the links to contact me on my home page https://seaecolab.netlify.com/ Cheers!\n","date":1535500800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535500800,"objectID":"e720509a72ce92d49ab80a6638740773","permalink":"/post/how-to-create-your-own-academic-website-like-a-noob/","publishdate":"2018-08-29T00:00:00Z","relpermalink":"/post/how-to-create-your-own-academic-website-like-a-noob/","section":"post","summary":"Welcome to this noob tutorial on how to get your own website online, quick and for free.\nFirst off you should know that this is NOT a complete guide on how to fully operate your future website and all the vast possibilities. I will happily lead you to the moment of the deployment and the emotion of having your own website on the web. To go further i suggest two main sources of great information that are:","tags":[],"title":"How to create your own academic website like a noob","type":"post"},{"authors":null,"categories":["SIG"],"content":"This is the page dedicated to the SIG101 course @UABCS. Slides can be found here\n Class 1 Class 2 Class 3\n Literature\n  ","date":1534896000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534896000,"objectID":"b6ce887b3915107e4129dea79aa0b868","permalink":"/post/sig101/","publishdate":"2018-08-22T00:00:00Z","relpermalink":"/post/sig101/","section":"post","summary":"This is the page dedicated to the SIG101 course @UABCS. Slides can be found here\n Class 1 Class 2 Class 3\n Literature\n  ","tags":["SIG"],"title":"SIG101: An Introduction to Geographic Information Systems","type":"post"},{"authors":null,"categories":null,"content":"This project is in collaboration with Dr. Morel, who has been developing 4SM methodology for water column correction of satellite images without the need for field data. We are proud to be part of the developing of this incredible method.\n4SM is also featured in a new project of mapping the benthic communities of the Espiritu Santo marine reserve. More information about the project are coming soon.\n","date":1534312800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534312800,"objectID":"7c1d9a194e327f645f924f839aefec53","permalink":"/project/remote-sensing/","publishdate":"2018-08-15T00:00:00-06:00","relpermalink":"/project/remote-sensing/","section":"project","summary":"Remote sensing technologies are applied to map coastal habitat dynamics of the rocky reefs in the Gulf of California to monitor their change over time","tags":["Remote Sensing"],"title":"Remote Sensing","type":"project"},{"authors":null,"categories":[],"content":"The SeaEcoLab aims to model how habitats and communities change in time, and how this affect biodiversity and ecosystem functioning. In the Gulf of California the group is working extensively using numerical ecology techniques, generalized models, and remote sensing to study rocky reefs communities. The group is involved in different projects and is collaborating with international institutions, such as the SCRIPPS institution of Oceanography, the Centro Marino para la Biodiversidad y Conservacion CMBC, the Bioengeneering and Environmental Science Laboratory BICA and the Reef Fauna Project PFA.\n","date":1534291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534291200,"objectID":"13ed9df2ed4db5359a2f95e419a96778","permalink":"/post/who-we-are/","publishdate":"2018-08-15T00:00:00Z","relpermalink":"/post/who-we-are/","section":"post","summary":"The SeaEcoLab aims to model how habitats and communities change in time, and how this affect biodiversity and ecosystem functioning. In the Gulf of California the group is working extensively using numerical ecology techniques, generalized models, and remote sensing to study rocky reefs communities. The group is involved in different projects and is collaborating with international institutions, such as the SCRIPPS institution of Oceanography, the Centro Marino para la Biodiversidad y Conservacion CMBC, the Bioengeneering and Environmental Science Laboratory BICA and the Reef Fauna Project PFA.","tags":[],"title":"Who we are","type":"post"},{"authors":null,"categories":null,"content":"\u0026hellip;\n","date":1530165600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530165600,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"/privacy/","publishdate":"2018-06-28T00:00:00-06:00","relpermalink":"/privacy/","section":"","summary":"\u0026hellip;","tags":null,"title":"Privacy Policy","type":"page"},{"authors":["F Favoretto","Y Morel","A Waddington","J Lopez-Calderon","M Cadena-Roa","A Blanco-Jarvio"],"categories":null,"content":"","date":1506751200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506751200,"objectID":"c2b111c41313bd03080c6eba18650fe6","permalink":"/publication/4sm_slc/","publishdate":"2017-09-30T00:00:00-06:00","relpermalink":"/publication/4sm_slc/","section":"publication","summary":"Satellite-derived bathymetry methods over coastal areas were developed to deliver basic and useful bathymetry information. However, the process is not straightforward, the main limitation being the need for field data. The Self-calibrated Spectral Supervised Shallow-water Modeler (4SM) method was tested to obtain coastal bathymetry without the use of any field data. Using Landsat-8 multispectral images from 2013 to 2016, a bathymetric time series was produced. Groundtruthed depths and an alternative method, Stumpf’s Band Ratio Algorithm, were used to verify the results. Retrieved (4SM) vs groundtruthed depths scored an average r2 (0.90), and a low error (RMSE = 1.47 m). 4SM also showed, over the whole time series, the same average accuracy of the control method (40%). Advantages, limitations and operability under complex atmosphere and water column conditions, and high and low-albedo bottom processing capabilities of 4SM are discussed. In conclusion, the findings suggest that 4SM is as accurate as the commonly used Stumpf’s method, the only difference being the independence of 4SM from previous field data, and the potential to deliver bottom spectral characteristics for further modeling. 4SM thus represents a significant advance in coastal remote sensing potential to obtain bathymetry and optical properties of the marine bottom.","tags":["Coastal Remote Sensing"],"title":"Testing of the 4SM Method in the Gulf of California Suggests Field Data Are not Needed to Derive Satellite Bathymetry","type":"publication"},{"authors":["Y Morel","F Favoretto"],"categories":null,"content":"","date":1502776800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502776800,"objectID":"c90b2a4a84dc5cf32e6d0c3fabf1b0ca","permalink":"/publication/4sm_yann/","publishdate":"2017-08-15T00:00:00-06:00","relpermalink":"/publication/4sm_yann/","section":"publication","summary":"All empirical water column correction methods have consistently been reported to require existing depth sounding data for the purpose of calibrating a simple depth retrieval model; they yield poor results over very bright or very dark bottoms. In contrast, we set out to (i) use only the relative radiance data in the image along with published data, and several new assumptions; (ii) in order to specify and operate the simplified radiative transfer equation (RTE); (iii) for the purpose of retrieving both the satellite derived bathymetry (SDB) and the water column corrected spectral reflectance over shallow seabeds. Sea truth regressions show that SDB depths retrieved by the method only need tide correction. Therefore it shall be demonstrated that, under such new assumptions, there is no need for (i) formal atmospheric correction; (ii) conversion of relative radiance into calibrated reflectance; or (iii) existing depth sounding data, to specify the simplified RTE and produce both SDB and spectral water column corrected radiance ready for bottom typing. Moreover, the use of the panchromatic band for that purpose is introduced. Altogether, we named this process the Self-Calibrated Supervised Spectral Shallow-sea Modeler (4SM). This approach requires a trained practitioner, though, to produce its results within hours of downloading the raw image. The ideal raw image should be a “near-nadir” view, exhibit homogeneous atmosphere and water column, include some coverage of optically deep waters and bare land, and lend itself to quality removal of haze, atmospheric adjacency effect, and sun/sky glint.","tags":["Coastal Remote Sensing"],"title":"4SM a novel method for water column correction","type":"publication"},{"authors":null,"categories":null,"content":"\u0026ldquo;The Gulf of California is famous all over the world for its marine biodiversity. There, rocky reefs represent the largest habitat that hosts a rich biodiversity important for the ecosystem balance and for providing commercial and tourist attractions. In the GOC, few studies tackled the topic of macroalgae community ecology in the rocky reefs, despite being a recognized fundamental component in every marine system. On a large scale, the relationship between macroalgae community structure and the surrounding environment is practically unknown. Here we show how macroalgae dominates in term of cover all of the rocky reefs investigated, underlining their importance for the habitat.\nBoxplots macroalgae taxa that showed the highest cover in the five study areas; the last panel show the top five taxa with the highest cover in all of the surveyed reefs, the abbreviations are L. var= Lobophora variegata, Dict= Dictyota sp, Poci= Pocillopora spp.\nFurthermore, we disentangled the role of abiotic factors, like temperature and Chlorophyll-a concentration, and biotic factors, like fish and invertebrate grazers, over the macroalgae community. We found a latitudinal gradient in macroalgae that, however, is not the most important driver of community structure at this scale. Indeed a strong relationship was found between macroalgae functional groups like turf and crustose coralline algae with grazing species like the sea urchin Diadema mexicanum and the starfish Phataria unifascialis.\nParsimonious RDA of macroalgae benthic community using biotic and abiotic environmental variables as explanatory variables. Significant variables represented by the arrows are coded as follow: D_mex: Diadema mexicanum, chla_min: Chlorophyll-a minimum value, SST: mean Sea Surface Temperature (°C), P_unif: Phataria unifascialis.\nThese results further underline the importance of the trophic network in keeping the balance between different functional groups of organisms, and the key role that grazer play in shaping community structure. We hope to raise interest over the macroalgae of the rocky reefs and that this study will serve as a baseline from which future investigation can rely on to further understand the complex relationships that shapes the rocky reefs communities in the GOC.\n","date":1461736800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461736800,"objectID":"b7b4bd3d84e86a4f65c02a024cc95090","permalink":"/project/macroalgae/","publishdate":"2016-04-27T00:00:00-06:00","relpermalink":"/project/macroalgae/","section":"project","summary":"Biotic and abiotic effects over rocky reef's macroalgae community strucutre, a neglected component in the Gulf of California","tags":["Macroalgae"],"title":"Macroalgae community over the rocky reefs in the Gulf of California","type":"project"},{"authors":null,"categories":null,"content":"\u0026ldquo;The Gulf of California, once branded as “the Aquarium of the World” due to its high biodiversity and pool of unique species, is subject to increasing fishing pressure and habitat transformation, threatening its biodiversity. Using a database of 17 years of ecological underwater surveys in the rocky reefs of the region, our temporal analyses revealed a generalized loss of richness for species of fishes and epibenthic invertebrates. Moreover, a significant rise of Sea Surface Temperatures (SST) is prompting a tropicalization of the invertebrate community in the region, where species that historically inhabited the subtropical transitional areas in the GOC, reduced their spatial range, while being displaced by species with tropical affinities. Analyzing community differences among reefs trough time using the Local Contribution to Beta Diversity index, we observed that the coupled effects of the defaunation and tropicalization prompted a spatial biotic homogenization over the region, making reefs more similar through time. On the left, the map show ecoregions in the GOC. NG is Northern GOC, CG is Central GOC, SG is Southern GOC, TEP is Tropical Eastern Pacific. On the right the same regions are drawn, but shifted northwards according to what we can theoretically expect for the future of the area from the results of this project. The purpose of this figure is just to allow the reader to visualize our conceptualization of a near-future tropicalization scenario in the GOC.\nFinally, we found that well-enforced no-take areas can buffer the long-term homogenization of specific reefs, such as Cabo Pulmo National Park. This suggest that overfishing might be an important driver of fish biomasses degradation in the region. The longer-term outcomes of the processes of defaunation, tropicalization and biotic homogenization over ecosystems are still largely unknown. Continuing the support of ecological monitoring programs is, therefore, far-reaching not only to record such effects, but also to identify areas that could serve as last refugia to preserve the biodiversity of a region that once attracted the attention of researchers from around the globe.\u0026rdquo;\n","date":1461736800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461736800,"objectID":"fc8cc1f59c43aa55c382a60788342022","permalink":"/project/rocky-reefs-community/","publishdate":"2016-04-27T00:00:00-06:00","relpermalink":"/project/rocky-reefs-community/","section":"project","summary":"Community ecology of fish and invertebrates associated to the rocky reefs in the Gulf of California. This project uses data from the Gulf of California Marine Program monitoring database.","tags":["Rocky reefs"],"title":"Rocky reefs' community ecology in the Gulf of California","type":"project"}]